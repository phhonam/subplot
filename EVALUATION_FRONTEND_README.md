# Movie Profile Evaluation Frontend System

A comprehensive web-based interface for evaluating and improving movie profile generation using LLM-based assessment tools.

## üéØ Overview

The evaluation frontend provides an intuitive web interface to:
- **Browse and search** your movie database
- **Select individual movies** for detailed evaluation
- **Generate ground truth** using expert-level LLM prompts
- **Run comprehensive evaluations** across 5 categories
- **Compare profiles** side-by-side with ground truth
- **Identify improvement areas** with detailed feedback
- **Validate system performance** against benchmark films
- **Run batch evaluations** for performance analysis

## üöÄ Quick Start

### 1. Start the Evaluation System
```bash
python3 start_evaluation_system.py
```

### 2. Access the Dashboard
The system will automatically open your browser to:
```
http://localhost:5001
```

### 3. Evaluate Movies
1. **Search or select** a movie from the dropdown
2. **Click "Evaluate Selected Movie"** to run comprehensive analysis
3. **Review results** including scores, feedback, and comparisons
4. **Use tabs** to switch between generated profile, ground truth, and side-by-side comparison

## üéõÔ∏è Features

### Movie Selection & Search
- **Search functionality**: Find movies by title, director, or genre
- **Dropdown selection**: Browse all movies in your database
- **Movie details**: View poster, plot, and current profile information

### Individual Movie Evaluation
- **Comprehensive scoring**: 5-category evaluation system
- **Overall quality score**: Weighted average across all categories
- **Category breakdown**: Detailed scores for each evaluation dimension
- **Expert feedback**: Specific suggestions for improvement

### Comparison Views
- **Generated Profile**: Current movie profile from your system
- **Ground Truth**: Expert-level reference profile generated by LLM
- **Side-by-Side**: Direct comparison of both profiles

### System Validation
- **Benchmark testing**: Validate against known films (Citizen Kane, Breathless, etc.)
- **Consistency checking**: Multi-model validation for reliability
- **Performance metrics**: Overall system quality assessment

### Batch Evaluation
- **Top 10 movies**: Quick performance assessment
- **Summary statistics**: Average scores and category performance
- **Individual results**: Detailed scores for each movie

## üìä Evaluation Categories

### 1. Cinema Movement & Genre Significance (20%)
- **Movement identification**: Correct film movement (French New Wave, Classical Hollywood, etc.)
- **Technique recognition**: Movement-specific techniques and innovations
- **Historical placement**: Position within cinema history
- **Genre contribution**: How the film contributed to or subverted its genre

### 2. Socio-Cultural-Historical Context (25%)
- **Temporal accuracy**: Correct historical period placement
- **Social specificity**: Specific social issues and themes
- **Cultural authenticity**: Filmmaker perspective and cultural context
- **Political relevance**: Political implications and contemporary events

### 3. Formal Cinematography Analysis (20%)
- **Technical accuracy**: Correct cinematographic techniques
- **Innovation recognition**: Groundbreaking technical achievements
- **Thematic connection**: Links between visual choices and themes
- **Style identification**: Distinctive visual approaches

### 4. Character Design & Plot Analysis (15%)
- **Structure recognition**: Narrative innovations (non-linear, etc.)
- **Character complexity**: Character archetypes and their subversion
- **Narrative innovation**: Unique storytelling approaches
- **Thematic purpose**: Connection between narrative choices and themes

### 5. Distinctiveness (20%)
- **Uniqueness identification**: What makes the film unique
- **Influence recognition**: Impact on subsequent cinema
- **Cultural impact**: Broader cultural significance
- **Awards/recognition**: Significant achievements and their meaning

## üîß API Endpoints

### Core Endpoints
- `GET /api/movies` - List all movies (with optional search)
- `GET /api/movie/<title>` - Get detailed movie profile
- `POST /api/evaluate/<title>` - Evaluate specific movie
- `POST /api/batch-evaluate` - Evaluate multiple movies
- `POST /api/validate-system` - Run system validation

### Response Format
```json
{
  "success": true,
  "evaluation": {
    "movie_title": "Citizen Kane",
    "overall_score": 4.2,
    "category_scores": {
      "cinema_movement": 4.5,
      "socio_cultural": 4.0,
      "formal_analysis": 4.3,
      "narrative_analysis": 4.1,
      "distinctiveness": 4.2
    },
    "detailed_feedback": {
      "cinema_movement": "Excellent identification of Classical Hollywood movement...",
      "socio_cultural": "Good historical context but missing specific events..."
    },
    "ground_truth": "Expert-generated reference profile...",
    "generated_profile": "Current system profile..."
  }
}
```

## üé® User Interface

### Dashboard Layout
- **Header**: System title and description
- **Sidebar**: Search, movie selection, and action buttons
- **Main Content**: Movie details, evaluation results, and comparisons

### Color-Coded Scoring
- **Green (4.0+)**: Excellent quality
- **Orange (3.0-3.9)**: Good quality, minor improvements needed
- **Red (<3.0)**: Needs significant improvement

### Interactive Elements
- **Search bar**: Real-time movie filtering
- **Dropdown**: Alphabetical movie selection
- **Tabs**: Switch between profile views
- **Loading indicators**: Progress feedback during evaluations

## üîç Usage Examples

### Evaluate a Single Movie
1. Search for "Citizen Kane" or select from dropdown
2. Click "Evaluate Selected Movie"
3. Wait for evaluation to complete (30-60 seconds)
4. Review overall score and category breakdown
5. Switch between tabs to compare profiles

### Run System Validation
1. Click "Validate System" button
2. Wait for benchmark testing to complete (2-3 minutes)
3. Review overall quality score and consistency metrics
4. Check which benchmark films performed best/worst

### Batch Evaluation
1. Click "Batch Evaluate (Top 10)" button
2. Wait for all evaluations to complete (5-10 minutes)
3. Review summary statistics and individual results
4. Identify patterns in category performance

## ‚öôÔ∏è Configuration

### Environment Variables
The system uses your existing `.env` file:
```bash
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key  # Optional
```

### Model Selection
Edit `evaluation_api.py` to change models:
```python
# Use GPT-4 for better accuracy (more expensive)
judge = LLMJudge(model="gpt-4", provider="openai")
ground_truth_generator = GroundTruthGenerator(model="gpt-4", provider="openai")

# Use GPT-3.5-turbo for cost efficiency (current default)
judge = LLMJudge(model="gpt-3.5-turbo", provider="openai")
```

### Port Configuration
Change the port in `start_evaluation_system.py`:
```python
app.run(debug=False, host='0.0.0.0', port=5001)  # Change port here
```

## üìà Performance Optimization

### Caching
- **Ground truth caching**: Consider implementing caching for frequently evaluated movies
- **Result storage**: Save evaluation results to avoid re-computation

### Batch Processing
- **Limit batch size**: Current limit is 10 movies for performance
- **Progress indicators**: Consider adding progress bars for large batches

### API Optimization
- **Async processing**: Consider implementing async evaluation for better performance
- **Rate limiting**: Implement rate limiting for API calls

## üêõ Troubleshooting

### Common Issues

#### "Failed to initialize evaluation system"
- **Check API keys**: Ensure OPENAI_API_KEY is set in `.env`
- **Check internet connection**: LLM calls require internet access
- **Check file permissions**: Ensure all Python files are readable

#### "Movie not found" errors
- **Check movie database**: Ensure `movie_profiles_merged.json` exists and is valid
- **Check movie titles**: Use exact titles as they appear in the database

#### Slow evaluation performance
- **Use GPT-3.5-turbo**: Faster and cheaper than GPT-4
- **Reduce batch size**: Evaluate fewer movies at once
- **Check API limits**: Ensure you're not hitting rate limits

#### Browser compatibility
- **Use modern browser**: Chrome, Firefox, Safari, or Edge
- **Enable JavaScript**: Required for interactive features
- **Check console**: Look for JavaScript errors in browser console

### Debug Mode
Enable debug mode in `evaluation_api.py`:
```python
app.run(debug=True, host='0.0.0.0', port=5001)
```

## üîÑ Integration with Existing System

### Using Results for Improvement
1. **Identify weak categories**: Focus on consistently low-scoring areas
2. **Update prompts**: Use feedback to improve your profile generation prompts
3. **Test improvements**: Re-evaluate movies after making changes
4. **Track progress**: Compare scores before and after improvements

### Automated Integration
Consider integrating evaluation into your existing workflow:
```python
# Example: Evaluate new profiles before deployment
def evaluate_new_profile(movie_data):
    evaluator = AutomatedEvaluationPipeline()
    result = evaluator.evaluate_movie_profiles([movie_data], sample_size=1)
    
    if result[0].overall_score >= 3.0:
        return True  # Deploy
    else:
        return False  # Flag for improvement
```

## üìö Additional Resources

- **Evaluation Framework**: See `MOVIE_PROFILE_EVALUATION_FRAMEWORK.md`
- **System Documentation**: See `EVALUATION_SYSTEM_README.md`
- **Prompt Improvements**: See `PROMPT_IMPROVEMENTS_SUMMARY.md`
- **Workflow Diagrams**: See `EVALUATION_WORKFLOW.md`

## üÜò Support

If you encounter issues:
1. **Check the logs**: Look for error messages in the terminal
2. **Verify requirements**: Ensure all dependencies are installed
3. **Test API keys**: Verify your OpenAI API key is working
4. **Check file permissions**: Ensure all files are readable

The evaluation frontend provides a powerful tool for systematically improving your movie profile generation system through data-driven analysis and expert-level feedback.
